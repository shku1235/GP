{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers, losses\n",
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras import callbacks\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D, Lambda, Cropping2D\n",
    "\n",
    "import pandas as pd\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('train_concepts.txt', delimiter=\":\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C0738276</td>\n",
       "      <td>btt-8-083Fig3;abcd-28-01-0087-g03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C1287716</td>\n",
       "      <td>ipej030157-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C0576088</td>\n",
       "      <td>aps-43-590-g001;aps-43-590-g002;aps-43-590-g00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C2332719</td>\n",
       "      <td>CRIRH2016-2019250.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C0796089</td>\n",
       "      <td>kjlm-31-49-g001;MGG3-4-599-g001;JPN-6-19-g004;...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0                                                  1\n",
       "0  C0738276                  btt-8-083Fig3;abcd-28-01-0087-g03\n",
       "1  C1287716                                      ipej030157-10\n",
       "2  C0576088  aps-43-590-g001;aps-43-590-g002;aps-43-590-g00...\n",
       "3  C2332719                              CRIRH2016-2019250.001\n",
       "4  C0796089  kjlm-31-49-g001;MGG3-4-599-g001;JPN-6-19-g004;..."
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = []\n",
    "for index, row in data[:50].iterrows():\n",
    "#     print index\n",
    "    for i in row[1].split(';'):\n",
    "#         print str(i)+';'+str(row[0])+';'+str(index)\n",
    "        res.append(str(i)+';'+str(row[0])+';'+str(index))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 0\n",
      "0                         btt-8-083Fig3;C0738276;0\n",
      "1                   abcd-28-01-0087-g03;C0738276;0\n",
      "2                         ipej030157-10;C1287716;1\n",
      "3                       aps-43-590-g001;C0576088;2\n",
      "4                       aps-43-590-g002;C0576088;2\n",
      "5                       aps-43-590-g005;C0576088;2\n",
      "6                       aps-43-590-g006;C0576088;2\n",
      "7                        JCIS-2-66-g002;C0576088;2\n",
      "8                        cios-4-77-g001;C0576088;2\n",
      "9     CRIM.ENDOCRINOLOGY2013-190962.002;C0576088;2\n",
      "10        CRIM.RADIOLOGY2013-235209.001;C0576088;2\n",
      "11                         prm-20-229-1;C0576088;2\n",
      "12             10195_2011_165_Fig1_HTML;C0576088;2\n",
      "13             10195_2011_165_Fig2_HTML;C0576088;2\n",
      "14                      JCAS-6-171-g001;C0576088;2\n",
      "15                     1476-0711-4-18-2;C0576088;2\n",
      "16                   eplasty14ic11_fig1;C0576088;2\n",
      "17                    kjim-14-2-94-16f4;C0576088;2\n",
      "18                 JMedLife-04-314-g001;C0576088;2\n",
      "19                      1546-0096-5-8-4;C0576088;2\n",
      "20                    EJHS2603-0301Fig2;C0576088;2\n",
      "21                    EJHS2603-0301Fig4;C0576088;2\n",
      "22                      IJN-25-317-g002;C0576088;2\n",
      "23                       JGID-5-85-g001;C0576088;2\n",
      "24                      JGID-6-125-g001;C0576088;2\n",
      "25                      JGID-6-125-g002;C0576088;2\n",
      "26                     AMHSR-4-968-g001;C0576088;2\n",
      "27                     1477-7819-4-95-2;C0576088;2\n",
      "28                             rju14702;C0576088;2\n",
      "29                poljradiol-79-51-g011;C0576088;2\n",
      "...                                            ...\n",
      "1643                   arm-38-861-g002;C0203177;43\n",
      "1644    CRIM.PSYCHIATRY2012-585303.001;C0203177;43\n",
      "1645                    SNI-4-151-g002;C0203177;43\n",
      "1646                       ebsj02057-2;C0203177;43\n",
      "1647                    JPN-10-82-g001;C0273098;44\n",
      "1648            sensors-17-00233-g007a;C1853942;45\n",
      "1649         marinedrugs-12-04231-g004;C0016576;46\n",
      "1650               ECAM2013-472973.013;C0016576;46\n",
      "1651                   ymj-46-491-g001;C0273444;47\n",
      "1652                     en-21-83-g004;C0273444;47\n",
      "1653               TSWJ2012-314038.001;C0273444;47\n",
      "1654                CRM2009-568142.001;C0273444;47\n",
      "1655                   JETS-03-82-g003;C0273444;47\n",
      "1656                   JETS-03-82-g004;C0273444;47\n",
      "1657                      JCB32923.f1a;C0273444;47\n",
      "1658                  IJPS-44-511-g001;C0273444;47\n",
      "1659                  IJPS-44-511-g002;C0273444;47\n",
      "1660                  IJPS-44-511-g008;C0273444;47\n",
      "1661             MOJ_Vol7_Issue1_49_F2;C0273444;47\n",
      "1662                    JCIS-4-16-g003;C0273444;47\n",
      "1663                    JCIS-4-16-g004;C0273444;47\n",
      "1664                CHSJ-40-4-281-fig1;C0455285;48\n",
      "1665          13054_2015_778_Fig5_HTML;C0455285;48\n",
      "1666                     CJ-10-20-g001;C0455285;48\n",
      "1667                  ijms-38-198-g002;C0455285;48\n",
      "1668                 1752-1947-6-211-2;C0455285;48\n",
      "1669                 1752-1947-6-211-3;C0455285;48\n",
      "1670                  IJD-60-521a-g003;C0455285;48\n",
      "1671             CRIEM2017-2656203.002;C0455285;48\n",
      "1672           167_2010_1100_Fig3_HTML;C0834774;49\n",
      "\n",
      "[1673 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "final_results = pd.DataFrame(\n",
    "    {\n",
    "        \"0\":res,\n",
    "    })\n",
    "print final_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results.to_csv('Final_prediction1000.csv',  index = False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1673 1673\n"
     ]
    }
   ],
   "source": [
    "now = pd.read_csv('/Users/sharath/Desktop/GP/sharath/Final_prediction1000.csv', delimiter=\";\", header=None)\n",
    "k = now[[2]].values\n",
    "res = np_utils.to_categorical(k)\n",
    "# print res[:5]\n",
    "leng =  res.shape[1]\n",
    "print len(now[0]), len(res)\n",
    "\n",
    "dataset_size  = len(now[0])\n",
    "\n",
    "# print now.head()\n",
    "\n",
    "labels = pd.DataFrame(res)\n",
    "# print labels.head()\n",
    "\n",
    "\n",
    "result = pd.concat([now, labels], axis=1, join_axes=[now.index])\n",
    "# print result.head()\n",
    "# result.to_csv(\"preprocessed.txt\", header=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgdim = 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_7 (Conv2D)            (None, 80, 80, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 40, 40, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 51200)             0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 500)               25600500  \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 50)                25050     \n",
      "=================================================================\n",
      "Total params: 25,626,446\n",
      "Trainable params: 25,626,446\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:2: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), padding=\"same\", activation=\"relu\", input_shape=(80, 80, 3...)`\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Convolution2D(32, (3, 3), input_shape = (imgdim, imgdim,3),border_mode = 'same', activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(500, activation = 'relu'))\n",
    "model.add(Dense(leng, activation = 'softmax')) \n",
    "\n",
    "# model = Sequential()\n",
    "# model.add(Lambda(lambda x: (x / 255.0) - 0.5, input_shape=(64,64,3)))\n",
    "# model.add(Conv2D(32, (5, 5), activation='relu', padding='same'))\n",
    "# model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "# model.add(Conv2D(64, (5, 5), activation='relu', padding='same'))\n",
    "# model.add(Flatten())\n",
    "# # model.add(Dense(512, activation='relu'))\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1673, 80, 80, 3)\n",
      "(1673, 50)\n"
     ]
    }
   ],
   "source": [
    "# diffrent working method \n",
    "\n",
    "datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "x = []\n",
    "y = []\n",
    "for index, row in now.iterrows():\n",
    "#     print index\n",
    "    name = row.values[0] \n",
    "#     y.append(res[index])\n",
    "\n",
    "    img = Image.open(\"/Users/sharath/Desktop/GP/CaptionTraining2018/\"+ name +\".jpg\")\n",
    "    img = img.resize((imgdim,imgdim)).convert('RGB')\n",
    "    temp = np.array(img)\n",
    "#     print temp.shape\n",
    "    x.append(temp)\n",
    "#     yield (x, y)\n",
    "# print x[0]\n",
    "X = np.array(x)\n",
    "print X.shape\n",
    "print res.shape\n",
    "\n",
    "datagen.fit(X)\n",
    "# model.fit_generator(datagen.flow(X,res, shuffle=True),steps_per_epoch=dataset_size, epochs=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch', 0)\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 3s 34ms/step - loss: 5.4516 - acc: 0.4300\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 7.7367 - acc: 0.5200\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 7.5755 - acc: 0.5300\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 7.7367 - acc: 0.5200\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 8.6723 - acc: 0.4600\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 9.0261 - acc: 0.4400\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 2s 24ms/step - loss: 8.0590 - acc: 0.5000\n",
      "Epoch 1/1\n",
      "100/100 [==============================] - 3s 26ms/step - loss: 6.9308 - acc: 0.5700\n",
      "Epoch 1/1\n"
     ]
    }
   ],
   "source": [
    "for e in range(10):\n",
    "    print('Epoch', e)\n",
    "    batches = 0\n",
    "    for x_batch, y_batch in datagen.flow(X,res, shuffle=True ,batch_size=100):\n",
    "        model.fit(x_batch, y_batch)\n",
    "        batches += 1\n",
    "        if batches >= len(x) / 32:\n",
    "            # we need to break the loop by hand because\n",
    "            # the generator loops indefinitely\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 80, 80, 3)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "T = []\n",
    "name = 'IJEM-16-371-g004'\n",
    "img = Image.open(\"/Users/sharath/Desktop/GP/CaptionTraining2018/\"+ name +\".jpg\")\n",
    "img = img.resize((imgdim,imgdim)).convert('RGB')\n",
    "T.append(np.array(img))\n",
    "# print test.shape\n",
    "X = np.array(T)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# datagen = ImageDataGenerator(\n",
    "#     featurewise_center=True,\n",
    "#     featurewise_std_normalization=True,\n",
    "#     rotation_range=20,\n",
    "#     width_shift_range=0.2,\n",
    "#     height_shift_range=0.2,\n",
    "#     horizontal_flip=True)\n",
    "\n",
    "# # compute quantities required for featurewise normalization\n",
    "# # (std, mean, and principal components if ZCA whitening is applied)\n",
    "# datagen.fit(x_train)\n",
    "\n",
    "# # # fits the model on batches with real-time data augmentation:\n",
    "# # model.fit_generator(datagen.flow(x_train, y_train, batch_size=32),\n",
    "# #                     steps_per_epoch=len(x_train) / 32, epochs=epochs)\n",
    "\n",
    "# # here's a more \"manual\" example\n",
    "# for e in range(epochs):\n",
    "#     print('Epoch', e)\n",
    "#     batches = 0\n",
    "#     for x_batch, y_batch in datagen.flow(x_train, y_train, batch_size=32):\n",
    "#         model.fit(x_batch, y_batch)\n",
    "#         batches += 1\n",
    "#         if batches >= len(x_train) / 32:\n",
    "#             # we need to break the loop by hand because\n",
    "#             # the generator loops indefinitely\n",
    "#             break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " # def generate_arrays_from_file():\n",
    "    \n",
    "#     while 1:\n",
    "#         f = open(path)\n",
    "#         for line in f:\n",
    "#             # create numpy arrays of input data\n",
    "#             # and labels, from each line in the file\n",
    "#             x, y = process_line(line)\n",
    "#             img = load_images(x)\n",
    "#             yield (img, y)\n",
    "#         f.close()\n",
    "\n",
    "        \n",
    "# model.fit_generator(generate_arrays_from_file(),steps_per_epoch='10',epochs=10)\n",
    "\n",
    "\n",
    "# log_dir = './tf-log/'\n",
    "# tb_cb = callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "# cbks = [tb_cb]\n",
    "\n",
    "# target_dir = './models/'\n",
    "# if not os.path.exists(target_dir):\n",
    "#   os.mkdir(target_dir)\n",
    "# model.save('./models/model.h5')\n",
    "# model.save_weights('./models/weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# T = []\n",
    "# name = 'aps-43-590-g001'\n",
    "# img = Image.open(\"/Users/sharath/Desktop/GP/CaptionTraining2018/\"+ name +\".jpg\")\n",
    "# img = img.resize((64,64)).convert('RGB')\n",
    "# T.append(np.array(img))\n",
    "# # print test.shape\n",
    "# X = np.array(T)\n",
    "# X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# def generate_arrays_from_file():\n",
    "#     for index, row in now.iterrows():\n",
    "#         print index\n",
    "#         x = row.values[0]\n",
    "#         y = res[index]\n",
    "#         img = Image.open(\"/Users/sharath/Desktop/GP/CaptionTraining2018/\"+ x +\".jpg\")\n",
    "#         T.append(np.array(img))\n",
    "#         X = np.array(T)\n",
    "#     yield (X, y)\n",
    "    \n",
    "# model.fit_generator(generate_arrays_from_file(),steps_per_epoch='1',epochs=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# log_dir = './tf-log/'\n",
    "# tb_cb = callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "# cbks = [tb_cb]\n",
    "\n",
    "# target_dir = './models/'\n",
    "# if not os.path.exists(target_dir):\n",
    "#   os.mkdir(target_dir)\n",
    "# model.save('./models/model.h5')\n",
    "# model.save_weights('./models/weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.metrics import accuracy_score\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# #from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# #run classification\n",
    "# clf=RandomForestClassifier()\n",
    "# clf.fit(X_train,y_train)\n",
    "\n",
    "# #now, make predictions from the classifier\n",
    "# y_predicts=clf.predict(X_val)\n",
    "# acc = accuracy_score(y_val, y_predicts)\n",
    "# print \"Val acc: \", round(acc,3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
