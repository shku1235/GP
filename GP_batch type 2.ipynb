{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers, losses\n",
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras import callbacks\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D, Lambda, Cropping2D\n",
    "\n",
    "import pandas as pd\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('train_concepts.txt', delimiter=\":\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C0738276</td>\n",
       "      <td>btt-8-083Fig3;abcd-28-01-0087-g03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C1287716</td>\n",
       "      <td>ipej030157-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C0576088</td>\n",
       "      <td>aps-43-590-g001;aps-43-590-g002;aps-43-590-g00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C2332719</td>\n",
       "      <td>CRIRH2016-2019250.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C0796089</td>\n",
       "      <td>kjlm-31-49-g001;MGG3-4-599-g001;JPN-6-19-g004;...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0                                                  1\n",
       "0  C0738276                  btt-8-083Fig3;abcd-28-01-0087-g03\n",
       "1  C1287716                                      ipej030157-10\n",
       "2  C0576088  aps-43-590-g001;aps-43-590-g002;aps-43-590-g00...\n",
       "3  C2332719                              CRIRH2016-2019250.001\n",
       "4  C0796089  kjlm-31-49-g001;MGG3-4-599-g001;JPN-6-19-g004;..."
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = []\n",
    "for index, row in data[:20].iterrows():\n",
    "#     print index\n",
    "    for i in row[1].split(';'):\n",
    "#         print str(i)+';'+str(row[0])+';'+str(index)\n",
    "        res.append(str(i)+';'+str(row[0])+';'+str(index))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                0\n",
      "0                        btt-8-083Fig3;C0738276;0\n",
      "1                  abcd-28-01-0087-g03;C0738276;0\n",
      "2                        ipej030157-10;C1287716;1\n",
      "3                      aps-43-590-g001;C0576088;2\n",
      "4                      aps-43-590-g002;C0576088;2\n",
      "5                      aps-43-590-g005;C0576088;2\n",
      "6                      aps-43-590-g006;C0576088;2\n",
      "7                       JCIS-2-66-g002;C0576088;2\n",
      "8                       cios-4-77-g001;C0576088;2\n",
      "9    CRIM.ENDOCRINOLOGY2013-190962.002;C0576088;2\n",
      "10       CRIM.RADIOLOGY2013-235209.001;C0576088;2\n",
      "11                        prm-20-229-1;C0576088;2\n",
      "12            10195_2011_165_Fig1_HTML;C0576088;2\n",
      "13            10195_2011_165_Fig2_HTML;C0576088;2\n",
      "14                     JCAS-6-171-g001;C0576088;2\n",
      "15                    1476-0711-4-18-2;C0576088;2\n",
      "16                  eplasty14ic11_fig1;C0576088;2\n",
      "17                   kjim-14-2-94-16f4;C0576088;2\n",
      "18                JMedLife-04-314-g001;C0576088;2\n",
      "19                     1546-0096-5-8-4;C0576088;2\n",
      "20                   EJHS2603-0301Fig2;C0576088;2\n",
      "21                   EJHS2603-0301Fig4;C0576088;2\n",
      "22                     IJN-25-317-g002;C0576088;2\n",
      "23                      JGID-5-85-g001;C0576088;2\n",
      "24                     JGID-6-125-g001;C0576088;2\n",
      "25                     JGID-6-125-g002;C0576088;2\n",
      "26                    AMHSR-4-968-g001;C0576088;2\n",
      "27                    1477-7819-4-95-2;C0576088;2\n",
      "28                            rju14702;C0576088;2\n",
      "29               poljradiol-79-51-g011;C0576088;2\n",
      "..                                            ...\n",
      "520                  IJEM-20-892-g002;C0035143;19\n",
      "521                   IDOJ-5-236-g004;C0035143;19\n",
      "522                   isd-46-223-g001;C0035143;19\n",
      "523                   isd-46-223-g004;C0035143;19\n",
      "524                  IJD-60-638f-g002;C0035143;19\n",
      "525              fphys-05-00149-g0004;C0035143;19\n",
      "526                    ce-47-346-g004;C0035143;19\n",
      "527                 IJCIIS-1-161-g001;C0035143;19\n",
      "528          10195_2012_185_Fig1_HTML;C0035143;19\n",
      "529               abc-108-05-0473-g04;C0035143;19\n",
      "530              JMedLife-03-242-g001;C0035143;19\n",
      "531                 kjae-59-S110-g001;C0035143;19\n",
      "532                  kjped-58-37-g002;C0035143;19\n",
      "533               abd-92-01-0121-gf01;C0035143;19\n",
      "534               BMRI2014-586060.001;C0035143;19\n",
      "535                  NAJMS-8-259-g001;C0035143;19\n",
      "536          12471_2011_201_Fig2_HTML;C0035143;19\n",
      "537                 cop-0003-0185-g01;C0035143;19\n",
      "538                    gr-07-023-g007;C0035143;19\n",
      "539    CRIM.CARDIOLOGY2013-897813.002;C0035143;19\n",
      "540    CRIM.CARDIOLOGY2013-897813.003;C0035143;19\n",
      "541                     TOCMJ-5-99_F1;C0035143;19\n",
      "542                    cmc-2009-125f1;C0035143;19\n",
      "543                  wjem-18-601-g001;C0035143;19\n",
      "544                  wjem-18-601-g002;C0035143;19\n",
      "545                  wjem-18-601-g004;C0035143;19\n",
      "546          12328_2013_445_Fig5_HTML;C0035143;19\n",
      "547           13008_2016_25_Fig6_HTML;C0035143;19\n",
      "548                    gr1_PMC4823566;C0035143;19\n",
      "549           1349-7235-56-0157-g001a;C0035143;19\n",
      "\n",
      "[550 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "final_results = pd.DataFrame(\n",
    "    {\n",
    "        \"0\":res,\n",
    "    })\n",
    "print final_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results.to_csv('Final_prediction1000.csv',  index = False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "550 550\n"
     ]
    }
   ],
   "source": [
    "now = pd.read_csv('/Users/sharath/Desktop/GP/sharath/Final_prediction1000.csv', delimiter=\";\", header=None)\n",
    "k = now[[2]].values\n",
    "res = np_utils.to_categorical(k)\n",
    "# print res[:5]\n",
    "leng =  res.shape[1]\n",
    "print len(now[0]), len(res)\n",
    "\n",
    "dataset_size  = len(now[0])\n",
    "\n",
    "# print now.head()\n",
    "\n",
    "labels = pd.DataFrame(res)\n",
    "# print labels.head()\n",
    "\n",
    "\n",
    "result = pd.concat([now, labels], axis=1, join_axes=[now.index])\n",
    "# print result.head()\n",
    "# result.to_csv(\"preprocessed.txt\", header=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgdim = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_8 (Conv2D)            (None, 150, 150, 32)      896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 75, 75, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 180000)            0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 500)               90000500  \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 20)                10020     \n",
      "=================================================================\n",
      "Total params: 90,011,416\n",
      "Trainable params: 90,011,416\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:2: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), padding=\"same\", activation=\"relu\", input_shape=(150, 150,...)`\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Convolution2D(32, (3, 3), input_shape = (imgdim, imgdim,3),border_mode = 'same', activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(500, activation = 'relu'))\n",
    "model.add(Dense(leng, activation = 'softmax')) \n",
    "\n",
    "# model = Sequential()\n",
    "# model.add(Lambda(lambda x: (x / 255.0) - 0.5, input_shape=(64,64,3)))\n",
    "# model.add(Conv2D(32, (5, 5), activation='relu', padding='same'))\n",
    "# model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "# model.add(Conv2D(64, (5, 5), activation='relu', padding='same'))\n",
    "# model.add(Flatten())\n",
    "# # model.add(Dense(512, activation='relu'))\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(550, 150, 150, 3)\n",
      "(550, 20)\n"
     ]
    }
   ],
   "source": [
    "# diffrent working method \n",
    "\n",
    "datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "x = []\n",
    "y = []\n",
    "for index, row in now.iterrows():\n",
    "#     print index\n",
    "    name = row.values[0] \n",
    "#     y.append(res[index])\n",
    "\n",
    "    img = Image.open(\"/Users/sharath/Desktop/GP/CaptionTraining2018/\"+ name +\".jpg\")\n",
    "    img = img.resize((imgdim,imgdim)).convert('RGB')\n",
    "    temp = np.array(img)\n",
    "#     print temp.shape\n",
    "    x.append(temp)\n",
    "#     yield (x, y)\n",
    "# print x[0]\n",
    "X = np.array(x)\n",
    "print X.shape\n",
    "print res.shape\n",
    "\n",
    "datagen.fit(X)\n",
    "# model.fit_generator(datagen.flow(X,res, shuffle=True),steps_per_epoch=dataset_size, epochs=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch', 0)\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 20s 101ms/step - loss: 10.5763 - acc: 0.2300\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 14s 71ms/step - loss: 10.5574 - acc: 0.3450\n",
      "Epoch 1/1\n",
      "150/150 [==============================] - 12s 79ms/step - loss: 11.1752 - acc: 0.3067\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 15s 74ms/step - loss: 10.8797 - acc: 0.3250\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 13s 66ms/step - loss: 11.6856 - acc: 0.2750\n",
      "Epoch 1/1\n",
      "150/150 [==============================] - 10s 64ms/step - loss: 11.0678 - acc: 0.3133\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 13s 66ms/step - loss: 11.6050 - acc: 0.2800\n",
      "Epoch 1/1\n",
      "200/200 [==============================] - 13s 63ms/step - loss: 10.9603 - acc: 0.3200\n"
     ]
    }
   ],
   "source": [
    "for e in range(1):\n",
    "    print('Epoch', e)\n",
    "    batches = 0\n",
    "    for x_batch, y_batch in datagen.flow(X,res,batch_size=200):\n",
    "        model.fit(x_batch, y_batch)\n",
    "        batches += 1\n",
    "        if batches >= 8:\n",
    "            # we need to break the loop by hand because\n",
    "            # the generator loops indefinitely\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 150, 150, 3)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "T = []\n",
    "name = '1349-7235-56-0157-g001a'\n",
    "img = Image.open(\"/Users/sharath/Desktop/GP/CaptionTraining2018/\"+ name +\".jpg\")\n",
    "img = img.resize((imgdim,imgdim)).convert('RGB')\n",
    "T.append(np.array(img))\n",
    "# print test.shape\n",
    "X = np.array(T)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# datagen = ImageDataGenerator(\n",
    "#     featurewise_center=True,\n",
    "#     featurewise_std_normalization=True,\n",
    "#     rotation_range=20,\n",
    "#     width_shift_range=0.2,\n",
    "#     height_shift_range=0.2,\n",
    "#     horizontal_flip=True)\n",
    "\n",
    "# # compute quantities required for featurewise normalization\n",
    "# # (std, mean, and principal components if ZCA whitening is applied)\n",
    "# datagen.fit(x_train)\n",
    "\n",
    "# # # fits the model on batches with real-time data augmentation:\n",
    "# # model.fit_generator(datagen.flow(x_train, y_train, batch_size=32),\n",
    "# #                     steps_per_epoch=len(x_train) / 32, epochs=epochs)\n",
    "\n",
    "# # here's a more \"manual\" example\n",
    "# for e in range(epochs):\n",
    "#     print('Epoch', e)\n",
    "#     batches = 0\n",
    "#     for x_batch, y_batch in datagen.flow(x_train, y_train, batch_size=32):\n",
    "#         model.fit(x_batch, y_batch)\n",
    "#         batches += 1\n",
    "#         if batches >= len(x_train) / 32:\n",
    "#             # we need to break the loop by hand because\n",
    "#             # the generator loops indefinitely\n",
    "#             break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " # def generate_arrays_from_file():\n",
    "    \n",
    "#     while 1:\n",
    "#         f = open(path)\n",
    "#         for line in f:\n",
    "#             # create numpy arrays of input data\n",
    "#             # and labels, from each line in the file\n",
    "#             x, y = process_line(line)\n",
    "#             img = load_images(x)\n",
    "#             yield (img, y)\n",
    "#         f.close()\n",
    "\n",
    "        \n",
    "# model.fit_generator(generate_arrays_from_file(),steps_per_epoch='10',epochs=10)\n",
    "\n",
    "\n",
    "# log_dir = './tf-log/'\n",
    "# tb_cb = callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "# cbks = [tb_cb]\n",
    "\n",
    "# target_dir = './models/'\n",
    "# if not os.path.exists(target_dir):\n",
    "#   os.mkdir(target_dir)\n",
    "# model.save('./models/model.h5')\n",
    "# model.save_weights('./models/weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# T = []\n",
    "# name = 'aps-43-590-g001'\n",
    "# img = Image.open(\"/Users/sharath/Desktop/GP/CaptionTraining2018/\"+ name +\".jpg\")\n",
    "# img = img.resize((64,64)).convert('RGB')\n",
    "# T.append(np.array(img))\n",
    "# # print test.shape\n",
    "# X = np.array(T)\n",
    "# X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# def generate_arrays_from_file():\n",
    "#     for index, row in now.iterrows():\n",
    "#         print index\n",
    "#         x = row.values[0]\n",
    "#         y = res[index]\n",
    "#         img = Image.open(\"/Users/sharath/Desktop/GP/CaptionTraining2018/\"+ x +\".jpg\")\n",
    "#         T.append(np.array(img))\n",
    "#         X = np.array(T)\n",
    "#     yield (X, y)\n",
    "    \n",
    "# model.fit_generator(generate_arrays_from_file(),steps_per_epoch='1',epochs=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# log_dir = './tf-log/'\n",
    "# tb_cb = callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "# cbks = [tb_cb]\n",
    "\n",
    "# target_dir = './models/'\n",
    "# if not os.path.exists(target_dir):\n",
    "#   os.mkdir(target_dir)\n",
    "# model.save('./models/model.h5')\n",
    "# model.save_weights('./models/weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from sklearn.metrics import accuracy_score\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# #from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# #run classification\n",
    "# clf=RandomForestClassifier()\n",
    "# clf.fit(X_train,y_train)\n",
    "\n",
    "# #now, make predictions from the classifier\n",
    "# y_predicts=clf.predict(X_val)\n",
    "# acc = accuracy_score(y_val, y_predicts)\n",
    "# print \"Val acc: \", round(acc,3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
