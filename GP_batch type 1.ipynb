{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/lib/python2.7/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras import optimizers, losses\n",
    "from keras.models import Sequential\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D\n",
    "from keras import callbacks\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D, Lambda, Cropping2D\n",
    "\n",
    "import pandas as pd\n",
    "from keras.utils import np_utils\n",
    "\n",
    "from PIL import Image\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('train_concepts.txt', delimiter=\":\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C0738276</td>\n",
       "      <td>btt-8-083Fig3;abcd-28-01-0087-g03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C1287716</td>\n",
       "      <td>ipej030157-10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C0576088</td>\n",
       "      <td>aps-43-590-g001;aps-43-590-g002;aps-43-590-g00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C2332719</td>\n",
       "      <td>CRIRH2016-2019250.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C0796089</td>\n",
       "      <td>kjlm-31-49-g001;MGG3-4-599-g001;JPN-6-19-g004;...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0                                                  1\n",
       "0  C0738276                  btt-8-083Fig3;abcd-28-01-0087-g03\n",
       "1  C1287716                                      ipej030157-10\n",
       "2  C0576088  aps-43-590-g001;aps-43-590-g002;aps-43-590-g00...\n",
       "3  C2332719                              CRIRH2016-2019250.001\n",
       "4  C0796089  kjlm-31-49-g001;MGG3-4-599-g001;JPN-6-19-g004;..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = []\n",
    "for index, row in data[:10].iterrows():\n",
    "#     print index\n",
    "    for i in row[1].split(';'):\n",
    "#         print str(i)+';'+str(row[0])+';'+str(index)\n",
    "        res.append(str(i)+';'+str(row[0])+';'+str(index))        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                0\n",
      "0                        btt-8-083Fig3;C0738276;0\n",
      "1                  abcd-28-01-0087-g03;C0738276;0\n",
      "2                        ipej030157-10;C1287716;1\n",
      "3                      aps-43-590-g001;C0576088;2\n",
      "4                      aps-43-590-g002;C0576088;2\n",
      "5                      aps-43-590-g005;C0576088;2\n",
      "6                      aps-43-590-g006;C0576088;2\n",
      "7                       JCIS-2-66-g002;C0576088;2\n",
      "8                       cios-4-77-g001;C0576088;2\n",
      "9    CRIM.ENDOCRINOLOGY2013-190962.002;C0576088;2\n",
      "10       CRIM.RADIOLOGY2013-235209.001;C0576088;2\n",
      "11                        prm-20-229-1;C0576088;2\n",
      "12            10195_2011_165_Fig1_HTML;C0576088;2\n",
      "13            10195_2011_165_Fig2_HTML;C0576088;2\n",
      "14                     JCAS-6-171-g001;C0576088;2\n",
      "15                    1476-0711-4-18-2;C0576088;2\n",
      "16                  eplasty14ic11_fig1;C0576088;2\n",
      "17                   kjim-14-2-94-16f4;C0576088;2\n",
      "18                JMedLife-04-314-g001;C0576088;2\n",
      "19                     1546-0096-5-8-4;C0576088;2\n",
      "20                   EJHS2603-0301Fig2;C0576088;2\n",
      "21                   EJHS2603-0301Fig4;C0576088;2\n",
      "22                     IJN-25-317-g002;C0576088;2\n",
      "23                      JGID-5-85-g001;C0576088;2\n",
      "24                     JGID-6-125-g001;C0576088;2\n",
      "25                     JGID-6-125-g002;C0576088;2\n",
      "26                    AMHSR-4-968-g001;C0576088;2\n",
      "27                    1477-7819-4-95-2;C0576088;2\n",
      "28                            rju14702;C0576088;2\n",
      "29               poljradiol-79-51-g011;C0576088;2\n",
      "..                                            ...\n",
      "111                     gr8_PMC3825995;C0018021;9\n",
      "112                     gr9_PMC3825995;C0018021;9\n",
      "113                    gr11_PMC3825995;C0018021;9\n",
      "114                  1752-1947-5-572-1;C0018021;9\n",
      "115                     JCIS-6-13-g005;C0018021;9\n",
      "116          40064_2014_1212_Fig3_HTML;C0018021;9\n",
      "117          40064_2014_1212_Fig4_HTML;C0018021;9\n",
      "118          40064_2014_1212_Fig5_HTML;C0018021;9\n",
      "119                   JFMPC-5-460-g001;C0018021;9\n",
      "120                   kjim-28-380-g001;C0018021;9\n",
      "121                   IJEM-17-228-g002;C0018021;9\n",
      "122                   IJEM-17-228-g003;C0018021;9\n",
      "123        IJEM-17-228-g004_PMC3683195;C0018021;9\n",
      "124                     gr3_PMC4723733;C0018021;9\n",
      "125                  1752-1947-4-258-1;C0018021;9\n",
      "126                   IJEM-15-138-g001;C0018021;9\n",
      "127                     gr1_PMC5199157;C0018021;9\n",
      "128       CRIM.MEDICINE2013-923129.001;C0018021;9\n",
      "129                    1749-7922-7-9-7;C0018021;9\n",
      "130                     jcb1821031af01;C0018021;9\n",
      "131                   kjim-26-218-g001;C0018021;9\n",
      "132                   IJEM-17-366-g001;C0018021;9\n",
      "133                   IJEM-16-371-g004;C0018021;9\n",
      "134                     gr5_PMC3920355;C0018021;9\n",
      "135                    PAMJ-22-72-g004;C0018021;9\n",
      "136                  1756-0500-6-467-1;C0018021;9\n",
      "137             ircmj-17-05-18342-g002;C0018021;9\n",
      "138                    JMAS-9-116-g003;C0018021;9\n",
      "139                   IJEM-16-460-g001;C0018021;9\n",
      "140                    AER-11-110-g003;C0018021;9\n",
      "\n",
      "[141 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "final_results = pd.DataFrame(\n",
    "    {\n",
    "        \"0\":res,\n",
    "    })\n",
    "print final_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results.to_csv('Final_prediction1000.csv',  index = False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "141 141\n",
      "                     0         1  2    0    1    2    3    4    5    6    7  \\\n",
      "0        btt-8-083Fig3  C0738276  0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "1  abcd-28-01-0087-g03  C0738276  0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "2        ipej030157-10  C1287716  1  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0   \n",
      "3      aps-43-590-g001  C0576088  2  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0   \n",
      "4      aps-43-590-g002  C0576088  2  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0   \n",
      "\n",
      "     8    9  \n",
      "0  0.0  0.0  \n",
      "1  0.0  0.0  \n",
      "2  0.0  0.0  \n",
      "3  0.0  0.0  \n",
      "4  0.0  0.0  \n"
     ]
    }
   ],
   "source": [
    "now = pd.read_csv('/Users/sharath/Desktop/GP/sharath/Final_prediction1000.csv', delimiter=\";\", header=None)\n",
    "k = now[[2]].values\n",
    "res = np_utils.to_categorical(k)\n",
    "print res[:5]\n",
    "leng =  res.shape[1]\n",
    "\n",
    "print len(now[0]), len(res)\n",
    "\n",
    "dataset_size  = len(now[0])\n",
    "\n",
    "# print now.head()\n",
    "\n",
    "labels = pd.DataFrame(res)\n",
    "# print labels.head()\n",
    "\n",
    "\n",
    "result = pd.concat([now, labels], axis=1, join_axes=[now.index])\n",
    "from sklearn.utils import shuffle\n",
    "# result = shuffle(result)\n",
    "print result.head()\n",
    "\n",
    "result.to_csv(\"preprocessed.txt\", header=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "imgdim = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_4 (Conv2D)            (None, 64, 64, 32)        896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 32768)             0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 500)               16384500  \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                5010      \n",
      "=================================================================\n",
      "Total params: 16,390,406\n",
      "Trainable params: 16,390,406\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:2: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), padding=\"same\", activation=\"relu\", input_shape=(64, 64, 3...)`\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Convolution2D(32, (3, 3), input_shape = (imgdim, imgdim,3),border_mode = 'same', activation = 'relu'))\n",
    "model.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(500, activation = 'relu'))\n",
    "model.add(Dense(leng, activation = 'softmax')) \n",
    "\n",
    "\n",
    "# model = Sequential()\n",
    "# model.add(Lambda(lambda x: (x / 255.0) - 0.5, input_shape=(64,64,3)))\n",
    "# model.add(Conv2D(32, (5, 5), activation='relu', padding='same'))\n",
    "# model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "# model.add(Conv2D(64, (5, 5), activation='relu', padding='same'))\n",
    "# model.add(Flatten())\n",
    "# # model.add(Dense(512, activation='relu'))\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "141/141 [==============================] - 47s 335ms/step - loss: 15.8934 - acc: 0.0142\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1816bc0f90>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def generate_arrays_from_file(path):\n",
    "    \n",
    "    def process_line(row):\n",
    "        temp =  row.split(',')\n",
    "#         print temp[0]\n",
    "        return temp[1:2], temp[4:]\n",
    "    def load_images(img):\n",
    "#         print img\n",
    "        img = Image.open(\"/Users/sharath/Desktop/GP/CaptionTraining2018/\"+ img[0] +\".jpg\")\n",
    "        img = img.resize((imgdim,imgdim)).convert('RGB')\n",
    "        T = (np.expand_dims(img,axis=0))\n",
    "        return T\n",
    "\n",
    "        \n",
    "    while 1:\n",
    "        f = open(path)\n",
    "        for line in f:\n",
    "            x,y = process_line(line)\n",
    "            img = load_images(x)\n",
    "            y = np.expand_dims(y,axis=0)\n",
    "#             print img.shape, y.shape\n",
    "            yield (img, y)\n",
    "        f.close()\n",
    "        \n",
    "path = '/Users/sharath/Desktop/GP/sharath/preprocessed.txt'\n",
    "\n",
    "    \n",
    "model.fit_generator(generate_arrays_from_file(path) ,steps_per_epoch=dataset_size, epochs=1)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 64, 64, 3)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T = []\n",
    "name = 'aps-43-590-g001'\n",
    "img = Image.open(\"/Users/sharath/Desktop/GP/CaptionTraining2018/\"+ name +\".jpg\")\n",
    "img = img.resize((imgdim,imgdim)).convert('RGB')\n",
    "T.append(np.array(img))\n",
    "X = np.array(T)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_genarator(track_index):\n",
    "    track_index = track_index\n",
    "    X = []\n",
    "    y = []\n",
    "    print  track_index\n",
    "    for index, row in testdata[track_index:track_index+plus_track_index].iterrows():\n",
    "#         print row.index\n",
    "        x = row.values[0]\n",
    "        label = row.values[3:]\n",
    "        x = row.values[0]\n",
    "        y.append(label)\n",
    "        img = Image.open(\"/Users/sharath/Desktop/GP/CaptionTraining2018/\"+ x +\".jpg\")\n",
    "        img = img.resize((imgdim,imgdim)).convert('RGB')\n",
    "        T = (np.array(img))\n",
    "        X.append(T)\n",
    "#         track_index =  index\n",
    "    X_train = np.array(X)\n",
    "    y_train = np.array(y)\n",
    "#     print X_train.shape, y_train.shape\n",
    "    return X_train, y_train\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# datagen = ImageDataGenerator(\n",
    "#     featurewise_center=True,\n",
    "#     featurewise_std_normalization=True,\n",
    "#     rotation_range=20,\n",
    "#     width_shift_range=0.2,\n",
    "#     height_shift_range=0.2,\n",
    "#     horizontal_flip=True)\n",
    "\n",
    "# # compute quantities required for featurewise normalization\n",
    "# # (std, mean, and principal components if ZCA whitening is applied)\n",
    "# datagen.fit(x_train)\n",
    "\n",
    "# # # fits the model on batches with real-time data augmentation:\n",
    "# # model.fit_generator(datagen.flow(x_train, y_train, batch_size=32),\n",
    "# #                     steps_per_epoch=len(x_train) / 32, epochs=epochs)\n",
    "\n",
    "# # here's a more \"manual\" example\n",
    "# for e in range(epochs):\n",
    "#     print('Epoch', e)\n",
    "#     batches = 0\n",
    "#     for x_batch, y_batch in datagen.flow(x_train, y_train, batch_size=32):\n",
    "#         model.fit(x_batch, y_batch)\n",
    "#         batches += 1\n",
    "#         if batches >= len(x_train) / 32:\n",
    "#             # we need to break the loop by hand because\n",
    "#             # the generator loops indefinitely\n",
    "#             break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " # def generate_arrays_from_file():\n",
    "    \n",
    "#     while 1:\n",
    "#         f = open(path)\n",
    "#         for line in f:\n",
    "#             # create numpy arrays of input data\n",
    "#             # and labels, from each line in the file\n",
    "#             x, y = process_line(line)\n",
    "#             img = load_images(x)\n",
    "#             yield (img, y)\n",
    "#         f.close()\n",
    "\n",
    "        \n",
    "# model.fit_generator(generate_arrays_from_file(),steps_per_epoch='10',epochs=10)\n",
    "\n",
    "\n",
    "# log_dir = './tf-log/'\n",
    "# tb_cb = callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "# cbks = [tb_cb]\n",
    "\n",
    "# target_dir = './models/'\n",
    "# if not os.path.exists(target_dir):\n",
    "#   os.mkdir(target_dir)\n",
    "# model.save('./models/model.h5')\n",
    "# model.save_weights('./models/weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# def generate_arrays_from_file():\n",
    "#     for index, row in now.iterrows():\n",
    "#         print index\n",
    "#         x = row.values[0]\n",
    "#         y = res[index]\n",
    "#         img = Image.open(\"/Users/sharath/Desktop/GP/CaptionTraining2018/\"+ x +\".jpg\")\n",
    "#         T.append(np.array(img))\n",
    "#         X = np.array(T)\n",
    "#     yield (X, y)\n",
    "    \n",
    "# model.fit_generator(generate_arrays_from_file(),steps_per_epoch='1',epochs=1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# log_dir = './tf-log/'\n",
    "# tb_cb = callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "# cbks = [tb_cb]\n",
    "\n",
    "# target_dir = './models/'\n",
    "# if not os.path.exists(target_dir):\n",
    "#   os.mkdir(target_dir)\n",
    "# model.save('./models/model.h5')\n",
    "# model.save_weights('./models/weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
