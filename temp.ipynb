{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Importing the Keras libraries and packages\n",
    "import self as self\n",
    "from keras.models import Sequential, load_model\n",
    "\n",
    "\"\"\"There are two basic ways of initialising a neural network, either by a sequence of layers or as a graph\"\"\"\n",
    "from keras.layers import Conv2D\n",
    "\"\"\"Since we are working on images here, which a basically 2 Dimensional arrays, we’re using Convolution 2-D,\n",
    "you may have to use Convolution 3-D while dealing with videos\"\"\"\n",
    "from keras.layers import MaxPooling2D\n",
    "\"\"\"There exist different types of pooling operations like Min Pooling, Mean Pooling, etc.\n",
    "Here in MaxPooling we need the maximum value pixel from the respective region of interest\"\"\"\n",
    "from keras.layers import Flatten\n",
    "\"\"\"Flattening is the process of converting all the resultant 2 dimensional arrays into a single long continuous linear vector\"\"\"\n",
    "from keras.layers import Dense\n",
    "\"\"\"In order to perform the full connection of the neural network\"\"\"\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\"\"\"In order to create synthetic data out of the same images by performing different type of operations on these images like flipping, rotating, blurring, etc\"\"\"\n",
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "\"\"\"Final predictions\"\"\"\n",
    "import h5py\n",
    "import math\n",
    "import os\n",
    "from scipy import ndimage\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "############################################### THE SEQUENTIAL MODEL ###############################################\n",
    "\"\"\"\n",
    "STEP1: CONVOLUTION\n",
    "We took the object which already has an idea of how our neural network is going to be(Sequential), then we added a convolution layer by using the “Conv2D” function.\n",
    "The Conv2D function is taking 4 arguments, the first is the number of filters i.e 32 here, the second argument is the shape each filter is going to be i.e 3x3 here,\n",
    "the third is the input shape and the type of image(RGB or Black and White)of each image i.e the input image our CNN is going to be taking is of a 64x64 resolution\n",
    "and “3” stands for RGB, which is a colour img, the fourth argument is the activation function we want to use, here ‘relu’ stands for a rectifier function.\n",
    "\"\"\"\n",
    "\n",
    "classifier = Sequential()\n",
    "classifier.add(Conv2D(32, (3, 3), input_shape = (64, 64, 3), activation = 'relu'))\n",
    "\n",
    "\"\"\"\n",
    "STEP2: POOLING\n",
    "Now, we need to perform pooling operation on the resultant feature maps we get after the convolution operation is done on an image. The primary aim of a pooling\n",
    "operation is to reduce the size of the images as much as possible, to reduce the total number of nodes for the upcoming layers.We start by taking our classifier\n",
    "object and add the pooling layer. We take a 2x2 matrix we’ll have minimum pixel loss and get a precise region where the feature are located.\n",
    "\"\"\"\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "\"\"\"\n",
    "STEP3: FLATTERN\n",
    "It’s time for us to now convert all the pooled images into a continuous vector through Flattening. Flattening is a very important step to understand. What we are\n",
    "basically doing here is taking the 2-D array, i.e pooled image pixels and converting them to a one dimensional single vector.\n",
    "\"\"\"\n",
    "classifier.add(Flatten())\n",
    "\n",
    "\"\"\"\n",
    "STEP4: FULL CONNECTION\n",
    "In this step we need to create a fully connected layer, and to this layer we are going to connect the set of nodes we got after the flattening step, these nodes\n",
    "will act as an input layer to these fully-connected layers. As this layer will be present between the input layer and output layer, we can refer to it a hidden layer.\n",
    "As you can see, Dense is the function to add a fully connected layer, ‘units’ is where we define the number of nodes that should be present in this hidden layer, these\n",
    "units value will be always between the number of input nodes and the output nodes but the art of choosing the most optimal number of nodes can be achieved only through\n",
    "experimental tries. Though it’s a common practice to use a power of 2. And the activation function will be a rectifier function.\n",
    "\"\"\"\n",
    "classifier.add(Dense(units = 50, activation = 'relu'))\n",
    "\n",
    "\"\"\"\n",
    "STEP5: DEFINE THE OUTPUT LAYER\n",
    "Now it’s time to initialise our output layer, which should contain only one node, as it is binary classification. This single node will give us a binary output of either a Cat or Dog.\n",
    "\"\"\"\n",
    "classifier.add(Dense(units = 21871, activation = 'softmax')) #For binary classification:units = 4\n",
    "\n",
    "############################################### COMPILATION ###############################################\n",
    "\"\"\"\n",
    "Optimizer parameter is to choose the stochastic gradient descent algorithm. Loss parameter is to choose the loss function.\n",
    "Finally, the metrics parameter is to choose the performance metric.\n",
    "\"\"\"\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "############################################### THE SEQUENTIAL MODEL ###############################################\n",
    "\"\"\"\n",
    "STEP1: CONVOLUTION\n",
    "We took the object which already has an idea of how our neural network is going to be(Sequential), then we added a convolution layer by using the “Conv2D” function.\n",
    "The Conv2D function is taking 4 arguments, the first is the number of filters i.e 32 here, the second argument is the shape each filter is going to be i.e 3x3 here,\n",
    "the third is the input shape and the type of image(RGB or Black and White)of each image i.e the input image our CNN is going to be taking is of a 64x64 resolution\n",
    "and “3” stands for RGB, which is a colour img, the fourth argument is the activation function we want to use, here ‘relu’ stands for a rectifier function.\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###############################################   TRAINING   ###############################################\n",
    "\"\"\"\n",
    "In order to prevent Overfitting(when you get a great training accuracy and very poor test accuracy), the images of the dataset need to be preprocessed. We are going to do\n",
    "this using keras.preprocessing library for doing the synthesising part as well as to prepare the training set as well as the test test set of images that are present in a properly\n",
    "structured directories, where the directory’s name is take as the label of all the images present in it. The cleaning consists in flipping, rotating, blurring, etc.\n",
    "\"\"\"\n",
    "#######MAybe I should use rescale = 1./255 for get predictions\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,shear_range = 0.2,zoom_range = 0.2,horizontal_flip = True)\n",
    "validation_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "training_set = train_datagen.flow_from_directory('training_set',target_size = (64, 64),batch_size = 32,class_mode = 'categorical')\n",
    "validation_set = validation_datagen.flow_from_directory('validation_set',target_size = (64, 64),batch_size = 32,class_mode = 'categorical')\n",
    "test_set = validation_datagen.flow_from_directory('test_set',target_size = (64, 64),batch_size = 32,class_mode = 'categorical')\n",
    "\n",
    "\"\"\"FITTING(‘steps_per_epoch’ holds the number of training images)\"\"\"\n",
    "classifier.fit_generator(training_set,steps_per_epoch = 4000,epochs = 12,validation_data = validation_set,validation_steps = 1000)#8000 2000\n",
    "\"\"\"Saving the weights into a file\"\"\"\n",
    "classifier.save_weights('4000_1000_12.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "###############################################  EVALUATION  ###############################################\n",
    "scores=classifier.evaluate_generator(test_set)\n",
    "print(\"[0] %s: %.2f%%\" % (classifier.metrics_names[0], scores[0]*100))\n",
    "print(\"[1] %s: %.2f%%\" % (classifier.metrics_names[1], scores[1]*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "###############################################  PREDICTION  ###############################################\n",
    "#model = load_model('model.h5')\n",
    "'''test_image = image.load_img('prediction_set/a.jpg', target_size = (64, 64))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)'''\n",
    "\n",
    "def softmax(z):\n",
    "    z_exp = [math.exp(i) for i in z]\n",
    "    sum_z_exp = sum(z_exp)\n",
    "    return [i / sum_z_exp for i in z_exp]\n",
    "\n",
    "\n",
    "prediction_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "prediction_set = prediction_datagen.flow_from_directory('prediction_set',target_size = (64, 64),batch_size = 32,class_mode = None)\n",
    "\n",
    "'''results = classifier.predict_generator(self.test_generator)\n",
    "predictions = np.argmax(results, axis=-1) #multiple categories\n",
    "label_map = (predictions.class_indices)\n",
    "label_map = dict((v,k) for k,v in label_map.items()) #flip k,v\n",
    "predictions = [label_map[k] for k in predictions]'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "results = classifier.predict_generator(prediction_set)\n",
    "predictions = np.argmax(results, axis=-1) #multiple categories\n",
    "\n",
    "print(\"Training dataset:\")\n",
    "print(training_set.classes)\n",
    "print(training_set.class_indices)\n",
    "print(\"Results\")\n",
    "print(softmax(results))\n",
    "print(softmax(results[1]))\n",
    "print(softmax(results[2]))\n",
    "print(softmax(results[3]))\n",
    "print(predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
